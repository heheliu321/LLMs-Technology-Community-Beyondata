## ã€Šå¤§æ¨¡å‹Agentå¼€å‘å®æˆ˜ã€‹ï¼ˆä½“éªŒè¯¾ï¼‰

# å¤šæ¨¡æ€RAGå¼•æ“å¼€å‘å®æˆ˜

# Part 2.ä»é›¶åˆ°ä¸€å¿«é€Ÿæ­å»ºå¤šæ¨¡æ€RAGå¼•æ“

- æœ¬æœŸå…¬å¼€è¯¾å››å¤§æ¨¡å—å†…å®¹

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250828194616411.png" alt="image-20250828194616411" style="zoom:50%;" />

- ã€æ¼”ç¤ºã€‘å®æ“é¡¹ç›®ä¸€ï¼šä»é›¶åˆ°ä¸€å¿«é€Ÿæ­å»ºå¤šæ¨¡æ€RAGç³»ç»Ÿ

<video src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/74cfd666d005af475500d97302823538_raw.mp4"></video>

- ã€æ¼”ç¤ºã€‘å®æ“é¡¹ç›®äºŒï¼šä¼ä¸šçº§å¤šæ¨¡æ€RAGç³»ç»Ÿå¼€å‘å®æˆ˜

<video src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/27f4b2e749af80e62b1a9e3900e30e3f_raw.mp4"></video>

- è¯¾ä»¶&ä»£ç &é¡¹ç›®æºç é¢†å–ï¼š

  <img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/f7c49313c41eaeb3a2b3b9e9240d9f1e.png" alt="f7c49313c41eaeb3a2b3b9e9240d9f1e" style="zoom:50%;" />

- æœ¬èŠ‚ç›®å½•

[toc]

## ä¸€ã€ç»“æ„è§£æé‡å»ºæ³•å¤šæ¨¡æ€æ£€ç´¢æµç¨‹

### 1. ä»é›¶åˆ°ä¸€å¿«é€Ÿæ­å»ºå¤šæ¨¡æ€RAGç³»ç»ŸåŸºæœ¬æ€è·¯

â€‹	æ¥ä¸‹æ¥å°±è®©æˆ‘ä»¬ä¸Šæ‰‹**ç»“æ„è§£æé‡å»ºæ³•**æ¥ä»é›¶æ­å»ºå¤šæ¨¡æ€æ£€ç´¢æµç¨‹ã€‚åœ¨å‰é¢å¯¹å¤šæ¨¡æ€ PDF æ£€ç´¢çš„éš¾ç‚¹ä¸ä¸»æµå¼€æºé¡¹ç›®çš„æ¢³ç†ä¹‹åï¼Œæˆ‘ä»¬å·²ç»å»ºç«‹èµ·ä¸€ä¸ªæ¸…æ™°çš„è®¤çŸ¥æ¡†æ¶ï¼šå•çº¯ä¾èµ–æ–‡æœ¬æ£€ç´¢æ— æ³•åº”å¯¹ PDF æ–‡æ¡£ä¸­å¤æ‚çš„å¤šæ¨¡æ€å†…å®¹ï¼Œè€Œä»…ä»…ä¾èµ– OCR ä¹Ÿéš¾ä»¥ä¿ç•™å®Œæ•´çš„ç»“æ„ä¿¡æ¯ã€‚**å› æ­¤ï¼ŒçœŸæ­£å¯è½åœ°çš„è§£å†³æ–¹æ¡ˆå¾€å¾€éœ€è¦ç»“åˆæ–‡æ¡£è§£æä¸ç»“æ„åŒ–é‡å»º**ã€‚

â€‹	æ¥ä¸‹æ¥å°±è®©æˆ‘ä»¬ä¸Šæ‰‹ **ç»“æ„è§£æé‡å»ºæ³•** æ¥ä»é›¶æ­å»ºå¤šæ¨¡æ€æ£€ç´¢æµç¨‹ã€‚æ‰€è°“â€œç»“æ„è§£æé‡å»ºâ€ï¼Œæœ¬è´¨ä¸Šæ˜¯å¯¹åŸå§‹ PDF æ–‡æ¡£è¿›è¡Œåˆ†å±‚è§£æï¼Œå°†å…¶ä¸­çš„ **æ ‡é¢˜ã€æ®µè½ã€è¡¨æ ¼ã€å›¾ç‰‡ã€å…¬å¼ç­‰å…ƒç´ é€ä¸€æŠ½å–**ï¼Œå¹¶ä¾æ®å…¶åœ¨æ–‡æ¡£ä¸­çš„ä½ç½®å’Œè¯­ä¹‰å…³ç³»é‡æ–°ç»„ç»‡ï¼Œå†è½¬åŒ–ä¸ºä¸€ç§æ›´é€‚åˆä¸‹æ¸¸æ£€ç´¢ç³»ç»Ÿï¼ˆå¦‚ RAGï¼‰çš„ç»“æ„åŒ–è¡¨ç¤ºå½¢å¼ã€‚

â€‹	åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»¥ **Unstructured + PaddleOCR** ä¸ºæ ¸å¿ƒå·¥å…·é“¾ï¼Œæ¼”ç¤ºå¦‚ä½•ä» PDF æ–‡æ¡£ä¸­è‡ªåŠ¨è§£æå¤šæ¨¡æ€å†…å®¹ï¼Œå¹¶å°†å…¶é‡å»ºä¸º **Markdown æ ¼å¼æ–‡æ¡£**ã€‚è¿™ä¸€è¿‡ç¨‹ä¸ä»…èƒ½ä¿ç•™æ®µè½çš„å±‚æ¬¡ç»“æ„ï¼Œè¿˜èƒ½æå–å¹¶æœ¬åœ°ä¿å­˜å›¾ç‰‡ã€è¡¨æ ¼ç­‰å…ƒç´ ï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä»½æ—¢å¯è¯»åˆå¯æ£€ç´¢çš„ä¸­é—´äº§ç‰©ï¼Œä¸ºåç»­çš„å‘é‡åŒ–ä¸çŸ¥è¯†æ£€ç´¢æ‰“ä¸‹åšå®åŸºç¡€ã€‚

- æœ€ç»ˆæ•ˆæœæ¼”ç¤ºï¼š

  **å¤šæ¨¡æ€PDFæ–‡æ¡£æ–‡å­—ã€æ ‡é¢˜ã€å›¾ç‰‡ã€è¡¨æ ¼å¤šæ¨¡æ€è¯†åˆ«**

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729190307115.png" alt="image-20250729190307115" style="zoom:50%;" />

**å¤šæ¨¡æ€PDFå›¾ç‰‡æ–‡å­—è¯†åˆ«ä¸è¡¨æ ¼å†…å®¹è¯†åˆ«**

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729190337343.png" alt="image-20250729190337343" style="zoom: 50%;" />

**å¤šæ¨¡æ€PDFé€†å‘è½¬åŒ–ä¸º**Markdown

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729190355225.png" alt="image-20250729190355225" style="zoom:50%;" />

**æ­å»ºAgentic RAGç³»ç»Ÿæ£€ç´¢å¤šæ¨¡æ€PDFæ–‡æ¡£**

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729190424638.png" alt="image-20250729190424638" style="zoom:50%;" />

**å¤šæ¨¡æ€PDFæ£€ç´¢+å›¾æ–‡å¹¶èŒ‚çš„æ£€ç´¢ç»“æœç”Ÿæˆ**

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/1753787080505.jpg" alt="1753787080505" style="zoom: 33%;" />

- æ¼”ç¤ºè§†é¢‘

  <video src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/74cfd666d005af475500d97302823538_raw.mp4"></video>

### 2. Unstructuredè¡¥å……ä»‹ç»

â€‹	**Unstructured** æ˜¯ç›®å‰ä¸šç•Œæœ€å…·å½±å“åŠ›çš„ **æ–‡æ¡£è§£æä¸é¢„å¤„ç†æ¡†æ¶ä¹‹ä¸€**ï¼Œç”± Unstructured-IO å›¢é˜Ÿå¼€æºå¹¶æŒç»­ç»´æŠ¤ã€‚ä¸ MarkItDown åå‘è½»é‡åŒ–çš„ Markdown è½¬æ¢ä¸åŒï¼ŒUnstructured æ›´å¼ºè°ƒ **å¤šæ¨¡æ€æ–‡æ¡£çš„ç»†ç²’åº¦åˆ†è§£ï¼ˆpartitioningï¼‰** ä¸ **ç»“æ„åŒ–è¾“å‡º**ã€‚

â€‹	è¯¥é¡¹ç›®çš„æ ¸å¿ƒè®¾è®¡ç†å¿µæ˜¯ï¼šæ— è®ºæ–‡æ¡£æ¥æºæ˜¯ **PDFã€Wordã€PPTã€HTMLã€E-mailï¼Œç”šè‡³æ˜¯å›¾åƒå’Œæ‰«æä»¶**ï¼Œéƒ½èƒ½å¤Ÿè¢«è§£æä¸ºä¸€ä¸ªä¸ªç»“æ„åŒ–çš„ **Elementï¼ˆå…ƒç´ ï¼‰å¯¹è±¡**ã€‚æ¯ä¸ª Element éƒ½å¸¦æœ‰å®Œæ•´çš„ **ç±»åˆ«ä¿¡æ¯ï¼ˆå¦‚ Titleã€Paragraphã€Tableã€Imageã€Listã€Formula ç­‰ï¼‰** å’Œ **å…ƒæ•°æ®ï¼ˆmetadataï¼Œå¦‚é¡µç ã€åæ ‡ã€ç½®ä¿¡åº¦ç­‰ï¼‰**ã€‚è¿™ç§è§£ææ–¹å¼ä¸ä»…èƒ½ä¿ç•™æ–‡æœ¬çš„å±‚æ¬¡é€»è¾‘ï¼Œè¿˜èƒ½ä¸ºä¸‹æ¸¸ä»»åŠ¡æä¾›å®šä½ä¿¡æ¯ï¼Œä»è€Œæ”¯æŒè¯¸å¦‚ **è¡¨æ ¼é‡å»ºã€å›¾åƒ OCRã€å…¬å¼è¯†åˆ«** ç­‰æ›´å¤æ‚çš„å¤šæ¨¡æ€å¤„ç†ã€‚

åœ¨ PDF åœºæ™¯ä¸­ï¼ŒUnstructured æä¾›äº†å¤šç§è§£æç­–ç•¥ï¼š

- **fast æ¨¡å¼**ï¼šä»…åˆ©ç”¨ PDF å†…ç½®æ–‡æœ¬å±‚ï¼Œå¿«é€Ÿæå–æ–‡å­—ï¼Œé€‚åˆæœºå™¨ç”Ÿæˆçš„ PDFã€‚
- **hi_res æ¨¡å¼**ï¼šç»“åˆ OCRï¼ˆæ”¯æŒ Tesseractã€PaddleOCR ç­‰ï¼‰ä¸ç‰ˆé¢åˆ†æï¼Œç²¾ç¡®åˆ†å‰²æ–‡æœ¬å—ã€è¡¨æ ¼ä¸å›¾ç‰‡ï¼Œé€‚åˆæ‰«æä»¶ä¸ç‰ˆé¢å¤æ‚çš„ PDFã€‚
- **chunking**ï¼šå¯ä»¥å°†è§£æç»“æœè¿›ä¸€æ­¥åˆ‡åˆ†ä¸ºé€‚åˆå‘é‡æ£€ç´¢çš„è¯­ä¹‰ç‰‡æ®µã€‚

â€‹	ä¸å…¶ä»–å·¥å…·ç›¸æ¯”ï¼ŒUnstructured çš„ä¸€å¤§ä¼˜åŠ¿åœ¨äº **é«˜åº¦å¯æ‰©å±•**ï¼šå®ƒæ—¢èƒ½ä½œä¸ºç‹¬ç«‹çš„ Python åº“ä½¿ç”¨ï¼Œä¹Ÿèƒ½ä»¥ **API æœåŠ¡å½¢å¼** éƒ¨ç½²ï¼Œç”šè‡³ä¸ LangChainã€Haystackã€LlamaIndex ç­‰ä¸»æµ RAG æ¡†æ¶æ— ç¼é›†æˆã€‚è¿™ç§çµæ´»æ€§ï¼Œä½¿å…¶åœ¨ **ä¼ä¸šçŸ¥è¯†ç®¡ç†ã€åˆè§„æ€§æ–‡æ¡£è§£æã€ç§‘ç ”è®ºæ–‡åˆ†æ** ç­‰åœºæ™¯ä¸­å¹¿æ³›åº”ç”¨ã€‚

â€‹	å› æ­¤ï¼ŒUnstructured å·²ç»æˆä¸º **å¤šæ¨¡æ€ PDF æ–‡æ¡£æ£€ç´¢** æŠ€æœ¯æ ˆä¸­çš„é‡è¦åŸºçŸ³ã€‚å®ƒä¸ä»…èƒ½æä¾›é«˜ç²¾åº¦çš„ç»“æ„åŒ–è§£æç»“æœï¼Œè¿˜èƒ½ä¸åç»­çš„å‘é‡æ•°æ®åº“ã€æ£€ç´¢æ¨¡å‹å’Œå¤§æ¨¡å‹æ¨ç†ç¯èŠ‚å½¢æˆå¤©ç„¶çš„è¡”æ¥ï¼Œæ˜¯ç›®å‰æœ€æ¥è¿‘â€œå·¥ä¸šçº§æ ‡å‡†â€çš„å¼€æºè§£å†³æ–¹æ¡ˆä¹‹ä¸€ã€‚

- é¡¹ç›®åœ°å€ï¼šhttps://github.com/Unstructured-IO/unstructured

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729184214642.png" alt="image-20250729184214642" style="zoom:50%;" />

- å®éªŒæ–‡æ¡£ç´ æ

  è¿™é‡Œæˆ‘ä»¬å…ˆå°è¯•ä½¿ç”¨ä¸€ä¸ªDemo PDFæ–‡æ¡£è¿›è¡Œæ£€ç´¢å°è¯•ï¼Œåœ¨è·‘é€šæµç¨‹ä¹‹åï¼Œæˆ‘ä»¬å†å°†æ–¹æ³•åº”ç”¨äºæ›´åŠ å¤æ‚çš„æ–‡æ¡£æ£€ç´¢ã€‚

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729190120092.png" alt="image-20250729190120092" style="zoom:50%;" />

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250828194851036.png" alt="image-20250828194851036" style="zoom:50%;" />

- æ›´å¤šå‚è€ƒå­¦ä¹ èµ„æ–™ï¼š
  - ã€Šå·¥ä¸šçº§æ™ºèƒ½ä½“å¼€å‘å®è·µï¼ŒLangChainä»é›¶å…¥é—¨ä¸æ™ºèƒ½ä½“å¼€å‘å®æˆ˜ï¼ã€‹https://www.bilibili.com/video/BV1pYKgzAE5C/
  - ã€Šè¶…è¶ŠLangChainï¼LangGraphå¿«é€Ÿå…¥é—¨ä¸æ™ºèƒ½ä½“å¼€å‘å®æˆ˜ï¼ã€‹https://www.bilibili.com/video/BV1Kx3CzyE6Q/


- ç›¸å…³è¯¾ä»¶ï¼š

  <img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250828195551744.png" alt="image-20250828195551744" style="zoom:50%;" />

ä¸‹å›¾æ‰«ç å³å¯é¢†å–ï¼š

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/f7c49313c41eaeb3a2b3b9e9240d9f1e.png" alt="f7c49313c41eaeb3a2b3b9e9240d9f1e" style="zoom: 25%;" />

## äºŒã€å¤šæ¨¡æ€PDFæ–‡æ¡£è§£ææµç¨‹

### 1. åŸºç¡€ç¯å¢ƒå‡†å¤‡

â€‹	åœ¨æ­£å¼ä¸Šæ‰‹ PDF â†’ Markdown çš„ç»“æ„åŒ–è§£æä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å…ˆå‡†å¤‡å¥½å®éªŒç¯å¢ƒã€‚ç”±äºæœ¬æ–‡çš„å®éªŒåœ¨ **Windows ç³»ç»Ÿ**ä¸Šè¿›è¡Œï¼Œä¸‹é¢çš„æ­¥éª¤ä¹Ÿä»¥ Windows ä¸ºä¾‹ã€‚æ•´ä½“æ€è·¯æ˜¯ï¼š**é…ç½® Python ç¯å¢ƒ â†’ å®‰è£…åŸºç¡€ä¾èµ– â†’ å®‰è£… OCR å¼•æ“ï¼ˆPaddleOCRï¼‰ â†’ å®‰è£… PDF å¤„ç†ä¸è¾…åŠ©åº“**ã€‚

#### 1.1 åˆ›å»º Python ç¯å¢ƒ

â€‹	å»ºè®®ä½¿ç”¨ **Python 3.9+**ï¼ˆæ¨è 3.10 æˆ– 3.11ï¼‰ï¼Œä»¥ä¿è¯å…¼å®¹æ€§ï¼ŒåŒæ—¶æ¨èä½¿ç”¨ `conda` æˆ– `venv` æ¥åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š

```bash
# ä½¿ç”¨ conda åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n pdf_rag python=3.10 -y
conda activate pdf_rag

# æˆ–ä½¿ç”¨ venv
python -m venv pdf_rag
pdf_rag\Scripts\activate
```

#### 1.2 å®‰è£…åŸºç¡€åº“

â€‹	æœ¬æ¬¡é¡¹ç›®éœ€è¦ä¾èµ–çš„æ ¸å¿ƒä¾èµ–åŒ…æ‹¬ï¼š

- **PyMuPDF (fitz)**ï¼šè´Ÿè´£è¯»å– PDF æ–‡ä»¶ã€æå–é¡µé¢å’Œå›¾ç‰‡ã€‚
- **matplotlib / pillow**ï¼šç”¨äºå¯è§†åŒ–å’Œå›¾åƒå¤„ç†ã€‚
- **unstructured**ï¼šå¾®è½¯ / LangChain æ¨èçš„ PDF æ–‡æ¡£è§£æåº“ï¼Œæ”¯æŒç»“æ„åŒ–åˆ†å—ã€‚
- **paddleocr**ï¼šOCR å¼•æ“ï¼Œç”¨äºæ–‡æœ¬åŒºåŸŸçš„è¯†åˆ«ã€‚

å®‰è£…å‘½ä»¤å¦‚ä¸‹ï¼š

```bash
pip install "unstructured[all-docs]"   # æ”¯æŒ PDF / Word / PPT / HTML ç­‰æ–‡æ¡£è§£æ
pip install paddlenlp paddleocr        # OCR å¼•æ“
pip install PyMuPDF pillow matplotlib  # PDF å’Œå›¾ç‰‡å¤„ç†
pip install html2text                  # ç”¨äº HTML è¡¨æ ¼è½¬ Markdown
```

âš ï¸ æ³¨æ„ï¼š

- `unstructured[all-docs]` ä¼šè‡ªåŠ¨å®‰è£… PDF è§£æç›¸å…³çš„ä¾èµ–ï¼ˆå¦‚ pdfminer, PyMuPDFï¼‰ã€‚
- `paddleocr` åœ¨ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼ˆä¸­è‹±æ–‡æ¨¡å‹ï¼‰ã€‚å¦‚æœç½‘ç»œä¸ç•…ï¼Œå¯ä»¥æå‰ä¸‹è½½åæ‰‹åŠ¨æŒ‡å®šè·¯å¾„ã€‚
- åœ¨ Windows ä¸Šå®‰è£… `paddleocr` æ—¶ï¼Œå¯èƒ½éœ€è¦å…ˆè£… **Visual C++ è¿è¡Œåº“**ï¼Œå¦åˆ™ä¼šé‡åˆ° `paddlepaddle` çš„åŠ¨æ€é“¾æ¥åº“é”™è¯¯ã€‚
- æ­¤å¤–ï¼Œå¯ä»¥æ·»åŠ `--index-url https://mirrors.huaweicloud.com/repository/pypi/simple`åä¸ºé•œåƒæºæ¥åŠ é€Ÿä¸‹è½½ã€‚

### 2.è½½å…¥ PDF å¹¶è¿›è¡Œå…ƒç´ æå–

â€‹	æœ‰äº†ä¾èµ–åº“ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨ `UnstructuredLoader` æ¥è§£æ PDF æ–‡æ¡£äº†ï¼Œå¯¹äºç»™å®šçš„æ–‡æ¡£ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‰ç…§å¦‚ä¸‹æ–¹å¼è¿›è¡Œè§£æï¼š

```python
from langchain_unstructured import UnstructuredLoader

file_path = "0.LangChainæŠ€æœ¯ç”Ÿæ€ä»‹ç».pdf"

loader_local = UnstructuredLoader(
    file_path=file_path,
    strategy="hi_res",              # é«˜åˆ†è¾¨ç‡æ¨¡å¼ï¼Œæ”¯æŒå¤æ‚æ–‡æ¡£
    infer_table_structure=True,     # è‡ªåŠ¨è§£æè¡¨æ ¼ç»“æ„
    ocr_languages="chi_sim+eng",    # æ”¯æŒä¸­è‹±æ–‡ OCR
    ocr_engine="paddleocr"          # æŒ‡å®š PaddleOCR ä½œä¸º OCR å¼•æ“
)

docs_local = []
for doc in loader_local.lazy_load():
    docs_local.append(doc)
    
docs_local
```

æ­¤æ—¶docs_localå°±åŒ…å«äº†æ¯ä¸ªè§£æçš„å…ƒç´ ï¼Œå…·ä½“è¿è¡Œæ•ˆæœå¦‚ä¸‹ï¼š

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729191519438.png" alt="image-20250729191519438" style="zoom:50%;" />

å…¶ä¸­æ¯ä¸ª `doc` éƒ½åŒ…å« `page_content`ï¼ˆæ–‡æœ¬å†…å®¹ï¼‰ä»¥åŠ `metadata`ï¼ˆé¡µç ã€åæ ‡ã€ç±»å‹ç­‰ï¼‰ã€‚è¿™å°±æ„å‘³ç€æˆ‘ä»¬çš„ PDF æ–‡æ¡£å·²ç»è¢«æ‹†è§£ä¸ºä¸€ä¸ªä¸ª **å¯æ£€ç´¢çš„åŸºæœ¬å•å…ƒ**ï¼Œæ¥ä¸‹æ¥ä¾¿å¯ä»¥è¿›ä¸€æ­¥åšç»“æ„åŒ–å¤„ç†ã€‚

ä»¥ä¸‹æ˜¯è¿™æ®µä»£ç çš„è¯¦ç»†è§£é‡Šï¼š

è¿™æ®µä»£ç çš„æ ¸å¿ƒç›®æ ‡æ˜¯**ç”¨ Unstructured + PaddleOCR ä» PDF ä¸­æå–ç»“æ„åŒ–å†…å®¹ï¼Œå¹¶è¾“å‡ºä¸ºæ–‡æ¡£å¯¹è±¡åˆ—è¡¨ã€‚**

```python
from langchain_unstructured import UnstructuredLoader
```

- å¯¼å…¥ `UnstructuredLoader`ï¼Œè¿™æ˜¯ LangChain å°è£…çš„ä¸€ä¸ªæ¥å£ï¼Œå¯ä»¥ç›´æ¥ç”¨æ¥åŠ è½½ PDF ç­‰éç»“æ„åŒ–æ–‡æ¡£ã€‚

------

```python
pythonå¤åˆ¶ç¼–è¾‘loader_local = UnstructuredLoader(
    file_path=file_path,
    strategy="hi_res",              # é«˜åˆ†è¾¨ç‡æ¨¡å¼ï¼Œæ”¯æŒå¤æ‚æ–‡æ¡£
    infer_table_structure=True,     # è‡ªåŠ¨è§£æè¡¨æ ¼ç»“æ„
    ocr_languages="chi_sim+eng",    # æ”¯æŒä¸­è‹±æ–‡ OCR
    ocr_engine="paddleocr"          # æŒ‡å®š PaddleOCR ä½œä¸º OCR å¼•æ“
)
```

- **`file_path`**ï¼šæŒ‡å®š PDF è·¯å¾„ã€‚
- **`strategy="hi_res"`**ï¼šé«˜åˆ†è¾¨ç‡ OCR æ¨¡å¼ï¼Œé€‚åˆå¤æ‚è¡¨æ ¼å’Œæ’ç‰ˆã€‚
- **`infer_table_structure=True`**ï¼šå¯ç”¨è¡¨æ ¼è§£æï¼ŒæŠŠè¡¨æ ¼æ¢å¤ä¸ºç»“æ„åŒ–æ•°æ®ã€‚
- **`ocr_languages="chi_sim+eng"`**ï¼šè®¾ç½® OCR æ”¯æŒç®€ä½“ä¸­æ–‡ + è‹±æ–‡ã€‚
- **`ocr_engine="paddleocr"`**ï¼šæŒ‡å®š OCR å¼•æ“ä¸º PaddleOCRï¼ˆç›¸æ¯” Tesseract æ›´å¼ºï¼‰

------

```python
pythonå¤åˆ¶ç¼–è¾‘docs_local = []
for doc in loader_local.lazy_load():
    docs_local.append(doc)
```

- **`lazy_load()`** ä¼šé€é¡µåŠ è½½ PDF å¹¶è°ƒç”¨ OCR/è§£æã€‚
- `doc` æ˜¯ LangChain çš„ **Document** å¯¹è±¡ï¼Œé‡Œé¢åŒ…å«ï¼š
  - `doc.page_content` â†’ æ–‡æœ¬å†…å®¹
  - `doc.metadata` â†’ é¢å¤–ä¿¡æ¯ï¼ˆé¡µç ã€åæ ‡ã€åˆ†ç±»ã€OCR ç½®ä¿¡åº¦ç­‰ï¼‰

æ¥ä¸‹æ¥ä¸ºäº†éªŒè¯å®é™…å…ƒç´ æå–æ•ˆæœï¼Œæˆ‘ä»¬è¿™é‡Œè¿›ä¸€æ­¥æŠŠ PDF é¡µé¢æ¸²æŸ“æˆå›¾ç‰‡ï¼Œå¹¶åœ¨ä¸Šé¢ç»˜åˆ¶å‡ºåˆ†å—æ¡†ï¼ˆæ ‡é¢˜ã€è¡¨æ ¼ã€å›¾ç‰‡ã€æ–‡æœ¬ç­‰ï¼‰ï¼Œå®ç°å¯è§†åŒ–ã€‚

```python
import fitz
import matplotlib.patches as patches
import matplotlib.pyplot as plt
from PIL import Image


def plot_pdf_with_boxes(pdf_page, segments):
    pix = pdf_page.get_pixmap()
    pil_image = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

    fig, ax = plt.subplots(1, figsize=(10, 10))
    ax.imshow(pil_image)
    categories = set()
    category_to_color = {
        "Title": "orchid",
        "Image": "forestgreen",
        "Table": "tomato",
    }
    for segment in segments:
        points = segment["coordinates"]["points"]
        layout_width = segment["coordinates"]["layout_width"]
        layout_height = segment["coordinates"]["layout_height"]
        scaled_points = [
            (x * pix.width / layout_width, y * pix.height / layout_height)
            for x, y in points
        ]
        box_color = category_to_color.get(segment["category"], "deepskyblue")
        categories.add(segment["category"])
        rect = patches.Polygon(
            scaled_points, linewidth=1, edgecolor=box_color, facecolor="none"
        )
        ax.add_patch(rect)

    # Make legend
    legend_handles = [patches.Patch(color="deepskyblue", label="Text")]
    for category in ["Title", "Image", "Table"]:
        if category in categories:
            legend_handles.append(
                patches.Patch(color=category_to_color[category], label=category)
            )
    ax.axis("off")
    ax.legend(handles=legend_handles, loc="upper right")
    plt.tight_layout()
    plt.show()


def render_page(doc_list: list, page_number: int, print_text=True) -> None:
    pdf_page = fitz.open(file_path).load_page(page_number - 1)
    page_docs = [
        doc for doc in doc_list if doc.metadata.get("page_number") == page_number
    ]
    segments = [doc.metadata for doc in page_docs]
    plot_pdf_with_boxes(pdf_page, segments)
    if print_text:
        for doc in page_docs:
            print(f"{doc.page_content}\n")
```

æ­¤æ—¶æˆ‘ä»¬å°±èƒ½çœ‹åˆ°æ¯ä¸€ä¸ªPDFé¡µé¢é‡Œé¢æå–çš„å…ƒç´ äº†ï¼š

```python
render_page(docs_local, 1)
```

![image-20250729192101655](https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729192101655.png)

```python
render_page(docs_local, 3)
```

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729193327578.png" alt="image-20250729193327578" style="zoom:50%;" />

è¡¨æ ¼è¯†åˆ«æ•ˆæœå¦‚ä¸‹ï¼š

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729193245049.png" alt="image-20250729193245049" style="zoom:50%;" />

å…·ä½“ä»£ç è§£é‡Šå¦‚ä¸‹ï¼š

```python
def plot_pdf_with_boxes(pdf_page, segments):
    pix = pdf_page.get_pixmap()
    pil_image = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
```

- ä½¿ç”¨ **PyMuPDF (`fitz`)** æŠŠä¸€é¡µ PDF æ¸²æŸ“ä¸ºåƒç´ å›¾ï¼ˆ`pixmap`ï¼‰ã€‚
- è½¬æ¢ä¸º PIL Imageï¼Œæ–¹ä¾¿åç»­å¯è§†åŒ–ã€‚

------

```python
    fig, ax = plt.subplots(1, figsize=(10, 10))
    ax.imshow(pil_image)
```

- ç”¨ matplotlib æ˜¾ç¤º PDF é¡µçš„å›¾åƒä½œä¸ºèƒŒæ™¯ã€‚

------

```python
    category_to_color = {
        "Title": "orchid",
        "Image": "forestgreen",
        "Table": "tomato",
    }
```

- å®šä¹‰ä¸åŒç±»åˆ«ï¼ˆæ ‡é¢˜ã€å›¾ç‰‡ã€è¡¨æ ¼ï¼‰å¯¹åº”çš„é«˜äº®é¢œè‰²ã€‚
- å…¶ä»–æœªå®šä¹‰ç±»åˆ«ï¼ˆä¾‹å¦‚æ™®é€šæ–‡æœ¬ï¼‰é»˜è®¤ç”¨ `deepskyblue`ã€‚

------

```python
    for segment in segments:
        points = segment["coordinates"]["points"]
        layout_width = segment["coordinates"]["layout_width"]
        layout_height = segment["coordinates"]["layout_height"]
```

- éå†æ‰€æœ‰ `segments`ï¼ˆè¿™äº›æ˜¯å‰é¢ Unstructured/OCR è¾“å‡ºçš„ç»“æœï¼Œæ¯ä¸ª segment å¯¹åº”ä¸€ä¸ªè¯†åˆ«å—ï¼‰ã€‚
- æ‹¿åˆ°æ¯ä¸ªå—çš„åæ ‡ï¼ˆé€šå¸¸æ˜¯ PDF é¡µé¢çš„ç›¸å¯¹åæ ‡ï¼Œå•ä½åŒ–ä¸º 0~1 æˆ–æ–‡æ¡£å°ºå¯¸ï¼‰ã€‚

------

```python
        scaled_points = [
            (x * pix.width / layout_width, y * pix.height / layout_height)
            for x, y in points
        ]
```

- åæ ‡ç¼©æ”¾ï¼šæŠŠé€»è¾‘åæ ‡æ˜ å°„åˆ°å®é™…åƒç´ åæ ‡ã€‚
- è¿™æ ·çŸ©å½¢æ¡†æ‰èƒ½ç²¾ç¡®è¦†ç›–åˆ°å›¾åƒä¸Šçš„æ­£ç¡®ä½ç½®ã€‚

------

```python
        rect = patches.Polygon(
            scaled_points, linewidth=1, edgecolor=box_color, facecolor="none"
        )
        ax.add_patch(rect)
```

- ä½¿ç”¨ **matplotlib.patches.Polygon** ç»˜åˆ¶å¤šè¾¹å½¢æ¡†ï¼ˆé€šå¸¸æ˜¯çŸ©å½¢ï¼‰ã€‚
- è®¾ç½® `edgecolor` è¡¨ç¤ºä¸åŒç±»å‹çš„é¢œè‰²ã€‚

------

```python
    legend_handles = [patches.Patch(color="deepskyblue", label="Text")]
```

- æ‰‹åŠ¨ç»˜åˆ¶å›¾ä¾‹ï¼Œå¸®åŠ©åŒºåˆ†ä¸åŒç±»å‹çš„æ ‡æ³¨æ¡†ã€‚

`render_page` å‡½æ•°

```python
def render_page(doc_list: list, page_number: int, print_text=True) -> None:
    pdf_page = fitz.open(file_path).load_page(page_number - 1)
```

- æ‰“å¼€ PDFï¼Œå®šä½åˆ°ç¬¬ `page_number` é¡µã€‚

```python
    page_docs = [
        doc for doc in doc_list if doc.metadata.get("page_number") == page_number
    ]
    segments = [doc.metadata for doc in page_docs]
```

- ä»è¯†åˆ«ç»“æœä¸­è¿‡æ»¤å‡ºå±äºè¯¥é¡µçš„æ‰€æœ‰ `doc`ï¼ˆsegmentï¼‰ã€‚
- æå–å®ƒä»¬çš„å…ƒæ•°æ®ï¼ˆ`metadata`ï¼Œé‡Œé¢æœ‰ `coordinates`ã€`category` ç­‰ä¿¡æ¯ï¼‰ã€‚

```python
    plot_pdf_with_boxes(pdf_page, segments)
```

- è°ƒç”¨ä¸Šé¢çš„æ–¹æ³•ï¼ŒæŠŠè¿™ä¸€é¡µç»˜åˆ¶å‡ºæ¥ï¼Œå¹¶åŠ ä¸Šåˆ†å—æ¡†ã€‚

```python
    if print_text:
        for doc in page_docs:
            print(f"{doc.page_content}\n")
```

- å¦‚æœéœ€è¦ï¼Œæ‰“å°å‡º OCR/è§£æå¾—åˆ°çš„å®é™…æ–‡æœ¬ã€‚

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250828200022457.png" alt="image-20250828200022457" style="zoom: 50%;" />

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/0d489e9d3c29af2d7f319171eac040d0.png" alt="0d489e9d3c29af2d7f319171eac040d0" style="zoom:50%;" />

### 3. PDFé€†å‘è½¬åŒ–ä¸ºmdæ–‡æ¡£

â€‹	è€Œæ›´è¿›ä¸€æ­¥çš„ï¼Œæˆ‘ä»¬å°±èƒ½å°†å…¶è½¬åŒ–ä¸ºmarkdownæ–‡æ¡£ï¼š

```python
import os
import fitz
from unstructured.partition.pdf import partition_pdf

pdf_path = "0.LangChainæŠ€æœ¯ç”Ÿæ€ä»‹ç».pdf"
output_dir = "pdf_images"
os.makedirs(output_dir, exist_ok=True)

# Step 1: æå–æ–‡æœ¬/ç»“æ„åŒ–å†…å®¹
elements = partition_pdf(
    filename=pdf_path,
    infer_table_structure=True,   # å¼€å¯è¡¨æ ¼ç»“æ„æ£€æµ‹
    strategy="hi_res",            # é«˜åˆ†è¾¨ç‡ OCRï¼Œé€‚åˆå¤æ‚è¡¨æ ¼
    ocr_languages="chi_sim+eng",  # ä¸­è‹±æ–‡æ··åˆè¯†åˆ«
    ocr_engine="paddleocr"        # æŒ‡å®š PaddleOCR å¼•æ“
)

# Step 2: æå–å›¾ç‰‡å¹¶ä¿å­˜
doc = fitz.open(pdf_path)
image_map = {}  # æ˜ å°„ page_num -> list of image paths

for page_num, page in enumerate(doc, start=1):
    image_map[page_num] = []
    for img_index, img in enumerate(page.get_images(full=True), start=1):
        xref = img[0]
        pix = fitz.Pixmap(doc, xref)
        img_path = os.path.join(output_dir, f"page{page_num}_img{img_index}.png")
        if pix.n < 5:  # RGB / Gray
            pix.save(img_path)
        else:  # CMYK è½¬ RGB
            pix = fitz.Pixmap(fitz.csRGB, pix)
            pix.save(img_path)
        image_map[page_num].append(img_path)
        
# Step 3: è½¬æ¢ä¸º Markdown
md_lines = []
inserted_images = set()  # ç”¨æ¥è®°å½•å·²ç»æ’å…¥è¿‡çš„å›¾ç‰‡ï¼Œé¿å…é‡å¤

for el in elements:
    cat = el.category
    text = el.text
    page_num = el.metadata.page_number

    if cat == "Title" and text.strip().startswith("- "):
        md_lines.append(text + "\n")
    elif cat == "Title":
        md_lines.append(f"# {text}\n")
    elif cat in ["Header", "Subheader"]:
        md_lines.append(f"## {text}\n")
    elif cat == "Table":
        if hasattr(el.metadata, "text_as_html") and el.metadata.text_as_html:
            from html2text import html2text
            md_lines.append(html2text(el.metadata.text_as_html) + "\n")
        else:
            md_lines.append(el.text + "\n")
    elif cat == "Image":
        # é¿å…é‡å¤æ’å…¥ï¼šåªæ’å…¥å½“å‰å›¾ç‰‡å¯¹åº”çš„æ–‡ä»¶
        for img_path in image_map.get(page_num, []):
            if img_path not in inserted_images:
                md_lines.append(f"![Image](./{img_path})\n")
                inserted_images.add(img_path)
    else:
        md_lines.append(text + "\n")

# Step 4: å†™å…¥ Markdown æ–‡ä»¶
output_md = "output.md"
with open(output_md, "w", encoding="utf-8") as f:
    f.write("\n".join(md_lines))

print(f"âœ… è½¬æ¢å®Œæˆï¼Œå·²ç”Ÿæˆ {output_md} å’Œ {output_dir}/ å›¾ç‰‡æ–‡ä»¶å¤¹")
```

è¿è¡Œç»“æŸåå³å¯çœ‹åˆ°åˆ›å»ºçš„mdæ–‡æ¡£ï¼š

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729192929848.png" alt="image-20250729192929848" style="zoom:50%;" />

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250828200056711.png" alt="image-20250828200056711" style="zoom:50%;" />

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/0d489e9d3c29af2d7f319171eac040d0.png" alt="0d489e9d3c29af2d7f319171eac040d0" style="zoom:50%;" />

å®Œæ•´ä»£ç è§£é‡Šå¦‚ä¸‹ï¼š

**1. åŸºç¡€å‡†å¤‡**

```python
import os
import fitz
from unstructured.partition.pdf import partition_pdf

pdf_path = "0.LangChainæŠ€æœ¯ç”Ÿæ€ä»‹ç».pdf"
output_dir = "pdf_images"
os.makedirs(output_dir, exist_ok=True)
```

- `fitz` â†’ PyMuPDF åº“ï¼Œç”¨æ¥è¯»å– PDFã€æå–å›¾ç‰‡ã€‚
- `partition_pdf` â†’ Unstructured æä¾›çš„ PDF è§£ææ¥å£ï¼Œå¯ä»¥è‡ªåŠ¨è°ƒç”¨ OCRã€‚
- è®¾ç½® PDF æ–‡ä»¶è·¯å¾„å’Œè¾“å‡ºç›®å½• `pdf_images`ï¼Œä¿å­˜æå–å‡ºçš„å›¾ç‰‡ã€‚

**2. Step 1ï¼šæå–æ–‡æœ¬ä¸ç»“æ„åŒ–å†…å®¹**

```python
elements = partition_pdf(
    filename=pdf_path,
    infer_table_structure=True,   # å¼€å¯è¡¨æ ¼ç»“æ„æ£€æµ‹
    strategy="hi_res",            # é«˜åˆ†è¾¨ç‡ OCRï¼Œé€‚åˆå¤æ‚è¡¨æ ¼
    ocr_languages="chi_sim+eng",  # ä¸­è‹±æ–‡æ··åˆè¯†åˆ«
    ocr_engine="paddleocr"        # æŒ‡å®š PaddleOCR å¼•æ“
)
```

- **æ ¸å¿ƒä½œç”¨**ï¼šè°ƒç”¨ Unstructured çš„åˆ†åŒºè§£æï¼ŒæŠŠ PDF åˆ‡åˆ†ä¸º **æ ‡é¢˜ã€æ­£æ–‡ã€è¡¨æ ¼ã€å›¾ç‰‡ç­‰å…ƒç´ **ã€‚
- `infer_table_structure=True` â†’ è¡¨æ ¼ä¼šè¢«è§£ææˆç»“æ„åŒ–æ•°æ®ã€‚
- `strategy="hi_res"` â†’ é«˜åˆ†è¾¨ç‡ OCRï¼Œèƒ½æ›´å¥½åœ°è¯†åˆ«å¤æ‚æ’ç‰ˆï¼ˆæ¯”å¦‚å­¦æœ¯è®ºæ–‡ï¼‰ã€‚
- `ocr_languages="chi_sim+eng"` â†’ åŒæ—¶æ”¯æŒä¸­æ–‡ç®€ä½“å’Œè‹±æ–‡ã€‚
- `ocr_engine="paddleocr"` â†’ ä½¿ç”¨ PaddleOCR å¼•æ“ï¼ˆæ¯”é»˜è®¤ Tesseract æ›´å¼ºå¤§ï¼‰ã€‚

è¿”å›çš„ `elements` æ˜¯ä¸€ä¸ª **Element åˆ—è¡¨**ï¼Œæ¯ä¸ªå…ƒç´ æœ‰ï¼š

- `.category` â†’ ç±»å‹ï¼ˆTitleã€Paragraphã€Tableã€Image â€¦ï¼‰
- `.text` â†’ æ–‡æœ¬å†…å®¹
- `.metadata` â†’ é¡µç ã€åæ ‡ã€è¡¨æ ¼çš„ HTML ç­‰ä¿¡æ¯

**3. Step 2ï¼šæå–å›¾ç‰‡å¹¶ä¿å­˜**

```python
doc = fitz.open(pdf_path)
image_map = {}  # æ˜ å°„ page_num -> list of image paths

for page_num, page in enumerate(doc, start=1):
    image_map[page_num] = []
    for img_index, img in enumerate(page.get_images(full=True), start=1):
        xref = img[0]
        pix = fitz.Pixmap(doc, xref)
        img_path = os.path.join(output_dir, f"page{page_num}_img{img_index}.png")
        if pix.n < 5:  # RGB / Gray
            pix.save(img_path)
        else:  # CMYK è½¬ RGB
            pix = fitz.Pixmap(fitz.csRGB, pix)
            pix.save(img_path)
        image_map[page_num].append(img_path)
```

- ä½¿ç”¨ `fitz` éå† PDF çš„æ¯ä¸€é¡µï¼Œæå–å›¾ç‰‡ã€‚
- æ¯å¼ å›¾ç‰‡ä¿å­˜ä¸º `page{é¡µç }_img{ç´¢å¼•}.png`ã€‚
- `pix.n < 5` â†’ è¯´æ˜æ˜¯ RGB æˆ–ç°åº¦å›¾ï¼Œå¯ä»¥ç›´æ¥ä¿å­˜ï¼›
- å¦åˆ™æ˜¯ **CMYK è‰²å½©ç©ºé—´**ï¼Œéœ€è¦è½¬ä¸º RGB å†ä¿å­˜ã€‚
- æœ€åå­˜å…¥ `image_map`ï¼Œä¾¿äºåç»­å’Œ Markdown å†…å®¹å¯¹åº”ã€‚

**4. Step 3ï¼šç»„è£… Markdown æ–‡æ¡£**

```python
md_lines = []
inserted_images = set()  # é¿å…é‡å¤æ’å…¥ç›¸åŒå›¾ç‰‡

for el in elements:
    cat = el.category
    text = el.text
    page_num = el.metadata.page_number
```

- éå†å‰é¢è§£æå‡ºçš„æ‰€æœ‰ `elements`ï¼Œæ ¹æ®ä¸åŒç±»å‹æ‹¼æ¥ Markdownã€‚

(1) æ ‡é¢˜

```python
    if cat == "Title" and text.strip().startswith("- "):
        md_lines.append(text + "\n")
    elif cat == "Title":
        md_lines.append(f"# {text}\n")
    elif cat in ["Header", "Subheader"]:
        md_lines.append(f"## {text}\n")
```

- `Title` â†’ è½¬æ¢ä¸º Markdown ä¸€çº§æ ‡é¢˜ `#`ã€‚
- `Header / Subheader` â†’ è½¬æ¢ä¸ºäºŒçº§æ ‡é¢˜ `##`ã€‚
- ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœæ ‡é¢˜å¼€å¤´æ˜¯ `- `ï¼Œè¯´æ˜å…¶å®æ˜¯åˆ—è¡¨é¡¹è€Œä¸æ˜¯æ ‡é¢˜ï¼Œç›´æ¥ä¿æŒåŸæ ·ã€‚

(2) è¡¨æ ¼

```python
    elif cat == "Table":
        if hasattr(el.metadata, "text_as_html") and el.metadata.text_as_html:
            from html2text import html2text
            md_lines.append(html2text(el.metadata.text_as_html) + "\n")
        else:
            md_lines.append(el.text + "\n")
```

- å¦‚æœè¡¨æ ¼æœ‰ HTML æ ¼å¼ï¼ˆ`text_as_html`ï¼‰ï¼Œç”¨ `html2text` è½¬æ¢ä¸º Markdown è¡¨æ ¼ã€‚
- å¦åˆ™ç›´æ¥å†™å…¥æ–‡æœ¬ã€‚

(3) å›¾ç‰‡

```python
    elif cat == "Image":
        for img_path in image_map.get(page_num, []):
            if img_path not in inserted_images:
                md_lines.append(f"![Image](./{img_path})\n")
                inserted_images.add(img_path)
```

- å¯¹ `Image` å…ƒç´ ï¼Œæ’å…¥å¯¹åº”çš„å›¾ç‰‡è·¯å¾„ã€‚
- ä½¿ç”¨ `inserted_images` é¿å…é‡å¤æ·»åŠ ç›¸åŒçš„å›¾ç‰‡ã€‚

(4) æ™®é€šæ–‡æœ¬

```python
    else:
        md_lines.append(text + "\n")
```

- å…¶ä½™æƒ…å†µï¼ˆæ­£æ–‡æ®µè½ç­‰ï¼‰ç›´æ¥ä½œä¸ºæ™®é€šæ–‡æœ¬å†™å…¥ã€‚

**5. Step 4ï¼šå†™å…¥ Markdown æ–‡ä»¶**

```python
output_md = "output.md"
with open(output_md, "w", encoding="utf-8") as f:
    f.write("\n".join(md_lines))

print(f"âœ… è½¬æ¢å®Œæˆï¼Œå·²ç”Ÿæˆ {output_md} å’Œ {output_dir}/ å›¾ç‰‡æ–‡ä»¶å¤¹")
```

- æŠŠæ‹¼æ¥å¥½çš„ Markdown è¡Œå†™å…¥ `output.md`ã€‚
- æ‰€æœ‰å›¾ç‰‡ä¿å­˜åœ¨ `pdf_images/` æ–‡ä»¶å¤¹ä¸­ã€‚
- æœ€ç»ˆå¾—åˆ°ä¸€ä¸ªç»“æ„åŒ–è‰¯å¥½çš„ **Markdown æ–‡ä»¶ + å›¾ç‰‡èµ„æºç›®å½•**ï¼Œå¯ç›´æ¥ç”¨äº RAGã€‚

## ä¸‰ã€æ­å»ºåŸºäºå¤šæ¨¡æ€MarkDownæ–‡æ¡£çš„Agentic RAGæ£€ç´¢å¼•æ“

â€‹	åœ¨è·‘é€šäº†å¤šæ¨¡æ€æ–‡æ¡£è½¬åŒ–ä¹‹åï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬åŸºäºè½¬åŒ–åçš„å¤šæ¨¡æ€MarkDownæ–‡æ¡£æ¥åˆ›å»ºä¸€ä¸ªAgentic RAGå¼•æ“ã€‚é¡¹ç›®å®Œæ•´ä»£ç å¦‚ä¸‹ï¼š

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250828200301511.png" alt="image-20250828200301511" style="zoom:50%;" />

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/0d489e9d3c29af2d7f319171eac040d0.png" alt="0d489e9d3c29af2d7f319171eac040d0" style="zoom:50%;" />

### 1. åŸºç¡€ç¯å¢ƒæ­å»º

- åˆ›å»ºé¡¹ç›®ä¸»ç›®å½•

  <img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729193618255.png" alt="image-20250729193618255" style="zoom:50%;" />

- å®‰è£…åŸºç¡€ä¾èµ–

  ```txt
  pydantic
  python-dotenv
  langgraph
  langchain-core
  langchain-deepseek
  langchain-tavily
  langsmith
  langchain-openai
  langchain-text-splitters
  langchain-community
  faiss-cpu
  langgraph_supervisor
  graphrag
  ```

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729193652244.png" alt="image-20250729193652244" style="zoom:50%;" />

è¾“å…¥å¦‚ä¸‹å‘½ä»¤å®Œæˆå®‰è£…ï¼š

```bash
pip install -r requirements.txt
```

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250828200707858.png" alt="image-20250828200707858" style="zoom:50%;" />

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/0d489e9d3c29af2d7f319171eac040d0.png" alt="0d489e9d3c29af2d7f319171eac040d0" style="zoom:50%;" />

- é…ç½®ç¯å¢ƒå˜é‡

  åˆ›å»º.envæ–‡ä»¶ï¼Œå¹¶è¾“å…¥å¦‚ä¸‹API-KEY

  ```bash
  DEEPSEEK_API_KEY=sk-c1a253**
  OPENAI_API_KEY=sk-proj-gE**
  LANGSMITH_TRACING=true
  LANGSMITH_API_KEY=lsv2_pt_b44**
  LANGSMITH_PROJECT=langraph_studio_chatbot
  ```

  <img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729193726443.png" style="zoom:50%;" />

- å®‰è£…å‰ç«¯æ¡†æ¶Agent Chat UI

```bash
# git config --global http.proxy http://127.0.0.1:10080
# git config --global https.proxy http://127.0.0.1:10080

git clone https://github.com/langchain-ai/agent-chat-ui.git

cd agent-chat-ui
```

<center><img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506271632108.png" alt="image-20250627163204939" style="zoom:50%;" />


ç„¶åå®‰è£…å‰ç«¯ä¾èµ–ï¼š

```bash
pnpm install
```

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506271635853.png" alt="image-20250627163550759" style="zoom:50%;" />

å®‰è£…LangGraphé¡¹ç›®éƒ¨ç½²å·¥å…·ï¼š

```bash
pip install -U "langgraph-cli[inmem]"
```

### 2. çŸ¥è¯†åº“æ£€ç´¢æ•°æ®é›†å‡†å¤‡

â€‹	æ¥ä¸‹æ¥æˆ‘ä»¬ç»§ç»­å‡†å¤‡æ£€ç´¢ç”¨çš„æ•°æ®é›†ï¼Œè¿™é‡Œæˆ‘ä»¬é‡‡ç”¨æ­¤å‰ç³»åˆ—å…¬å¼€è¯¾ã€ŠMCPæŠ€æœ¯å®æˆ˜ã€‹è¯¾ä»¶ä½œä¸ºæ£€ç´¢ææ–™ï¼Œè¯¾ä»¶æ€»å…±çº¦6ä¸‡å­—ï¼Œå†…å®¹å¦‚ä¸‹ï¼š

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729194311218.png" alt="image-20250729194311218" style="zoom:33%;" />

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729194233098.png" alt="image-20250729194233098" style="zoom:50%;" />

ç½‘ç›˜å¯¹åº”åœ°å€å¦‚ä¸‹ï¼š

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250828200346504.png" style="zoom:50%;" />

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/0d489e9d3c29af2d7f319171eac040d0.png" alt="0d489e9d3c29af2d7f319171eac040d0" style="zoom:50%;" />

æ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦å…ˆå°†å…¶é€†å‘è½¬åŒ–ä¸ºmdæ–‡æ¡£ï¼š

```python
import os
import fitz
from unstructured.partition.pdf import partition_pdf

pdf_path = "MCPå®æˆ˜è¯¾ä»¶ã€åˆé›†ã€‘.pdf"
output_dir = "pdf_images"
os.makedirs(output_dir, exist_ok=True)

# Step 1: æå–æ–‡æœ¬/ç»“æ„åŒ–å†…å®¹
elements = partition_pdf(
    filename=pdf_path,
    infer_table_structure=True,   # å¼€å¯è¡¨æ ¼ç»“æ„æ£€æµ‹
    strategy="hi_res",            # é«˜åˆ†è¾¨ç‡ OCRï¼Œé€‚åˆå¤æ‚è¡¨æ ¼
    ocr_languages="chi_sim+eng",  # ä¸­è‹±æ–‡æ··åˆè¯†åˆ«
    ocr_engine="paddleocr"        # æŒ‡å®š PaddleOCR å¼•æ“
)

# Step 2: æå–å›¾ç‰‡å¹¶ä¿å­˜
doc = fitz.open(pdf_path)
image_map = {}  # æ˜ å°„ page_num -> list of image paths

for page_num, page in enumerate(doc, start=1):
    image_map[page_num] = []
    for img_index, img in enumerate(page.get_images(full=True), start=1):
        xref = img[0]
        pix = fitz.Pixmap(doc, xref)
        img_path = os.path.join(output_dir, f"page{page_num}_img{img_index}.png")
        if pix.n < 5:  # RGB / Gray
            pix.save(img_path)
        else:  # CMYK è½¬ RGB
            pix = fitz.Pixmap(fitz.csRGB, pix)
            pix.save(img_path)
        image_map[page_num].append(img_path)
# Step 3: è½¬æ¢ä¸º Markdown
md_lines = []
inserted_images = set()  # ç”¨æ¥è®°å½•å·²ç»æ’å…¥è¿‡çš„å›¾ç‰‡ï¼Œé¿å…é‡å¤

for el in elements:
    cat = el.category
    text = el.text
    page_num = el.metadata.page_number

    if cat == "Title" and text.strip().startswith("- "):
        md_lines.append(text + "\n")
    elif cat == "Title":
        md_lines.append(f"# {text}\n")
    elif cat in ["Header", "Subheader"]:
        md_lines.append(f"## {text}\n")
    elif cat == "Table":
        if hasattr(el.metadata, "text_as_html") and el.metadata.text_as_html:
            from html2text import html2text
            md_lines.append(html2text(el.metadata.text_as_html) + "\n")
        else:
            md_lines.append(el.text + "\n")
    elif cat == "Image":
        # é¿å…é‡å¤æ’å…¥ï¼šåªæ’å…¥å½“å‰å›¾ç‰‡å¯¹åº”çš„æ–‡ä»¶
        for img_path in image_map.get(page_num, []):
            if img_path not in inserted_images:
                md_lines.append(f"![Image](./{img_path})\n")
                inserted_images.add(img_path)
    else:
        md_lines.append(text + "\n")

# Step 4: å†™å…¥ Markdown æ–‡ä»¶
output_md = "output.md"
with open(output_md, "w", encoding="utf-8") as f:
    f.write("\n".join(md_lines))

print(f"âœ… è½¬æ¢å®Œæˆï¼Œå·²ç”Ÿæˆ {output_md} å’Œ {output_dir}/ å›¾ç‰‡æ–‡ä»¶å¤¹")
```

ç”Ÿæˆmdæ–‡æ¡£ï¼š

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729194546998.png" alt="image-20250729194546998" style="zoom:50%;" />

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250828200415496.png" alt="image-20250828200415496" style="zoom:50%;" />

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/0d489e9d3c29af2d7f319171eac040d0.png" alt="0d489e9d3c29af2d7f319171eac040d0" style="zoom:50%;" />

> æ³¨ï¼Œmdç‰ˆè¯¾ä»¶ç»Ÿä¸€è¿›è¡Œäº†å›¾åºŠä¸Šä¼ ï¼Œå¹¶ä¸”æŒ‰ç…§æ­£åˆ™è§„åˆ™è¿›è¡Œäº†æ•°æ®æ¸…æ´—ï¼Œæ•´ä½“æ–‡æ¡£ç»“æ„æ›´åŠ è§„èŒƒã€‚

ç„¶åï¼Œä¸ºäº†æ­å»ºRAGç³»ç»Ÿï¼Œæˆ‘ä»¬è¿˜éœ€è¦å¯¹åŸå§‹æ–‡æ¡£è¿›è¡Œå¤„ç†ï¼Œæ¥åˆ›å»ºè¯å‘é‡æ•°æ®åº“ï¼š

```python
OPENAI_EMBEDDING_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_EMBEDDING_BASE_URL = "https://ai.devtool.tech/proxy/v1"

from langchain_openai import OpenAIEmbeddings

embed = OpenAIEmbeddings(
    api_key=OPENAI_EMBEDDING_API_KEY,
    base_url=OPENAI_EMBEDDING_BASE_URL,
    model="text-embedding-3-small" 
)

# ! pip install langchain-text-splitters faiss-cpu --index-url https://pypi.tuna.tsinghua.edu.cn/simple

file_path = "MCPå®æˆ˜è¯¾ä»¶ã€åˆé›†ã€‘.md"

with open(file_path, "r", encoding="utf-8") as f:
    md_content = f.read()
    
from langchain_text_splitters import MarkdownHeaderTextSplitter

headers_to_split_on = [
    ("#", "Header 1"),
    ("##", "Header 2")
]

markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)
md_header_splits = markdown_splitter.split_text(md_content)

vector_store = FAISS.from_documents(md_header_splits, embedding=embed)
vector_store.save_local("telco_customer_churn_analytics_handbook")
```

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250728201922805.png" alt="image-20250728201922805" style="zoom:50%;" />

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250729194729951.png" alt="image-20250729194729951" style="zoom:50%;" />

ç”Ÿæˆçš„è¯å‘é‡æ•°æ®åº“å¦‚ä¸‹ï¼š

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250828200517895.png" alt="image-20250828200517895" style="zoom:50%;" />

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/0d489e9d3c29af2d7f319171eac040d0.png" alt="0d489e9d3c29af2d7f319171eac040d0" style="zoom:50%;" />

### 3. å¤šæ¨¡æ€RAGç³»ç»Ÿå¼€å‘

â€‹	æ¥ä¸‹æ¥ç¼–å†™å¤šæ¨¡æ€RAGç³»ç»Ÿä»£ç ï¼š

```python
from __future__ import annotations

import os
import asyncio
from typing import Literal
from dotenv import load_dotenv 
load_dotenv(override=True)
from langchain.chat_models import init_chat_model
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.tools.retriever import create_retriever_tool
from langgraph.graph import MessagesState, StateGraph, START, END
from langgraph.prebuilt import ToolNode, tools_condition
from pydantic import BaseModel, Field

# ---------------------------------------------------------------------------
# LLM & Embeddings
# ---------------------------------------------------------------------------
MODEL_NAME = "deepseek-chat"
model = init_chat_model(model=MODEL_NAME, model_provider="deepseek", temperature=0)
grader_model = init_chat_model(model=MODEL_NAME, model_provider="deepseek", temperature=0)

embed = OpenAIEmbeddings(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url="https://ai.devtool.tech/proxy/v1",
    model="text-embedding-3-small",
)

# ---------------------------------------------------------------------------
# Vector store & Retriever tool
# ---------------------------------------------------------------------------
VS_PATH = "mcp_course_materials_db"

vector_store = FAISS.load_local(
    folder_path=VS_PATH,
    embeddings=embed,
    allow_dangerous_deserialization=True,
)
retriever_tool = create_retriever_tool(
    vector_store.as_retriever(search_kwargs={"k": 3}),
    name="retrieve_mcp_course",
    description="Search and return relevant sections from the mcp course materials.",
)

# ---------------------------------------------------------------------------
# Prompts
# ---------------------------------------------------------------------------
SYSTEM_INSTRUCTION = (
    "You are an MCP technical training assistant. 'MCP' refers to **Model Context Protocol**, "
    "an open framework for enabling LLMs to call external tools. Do NOT confuse it with Microsoft Certified Professional.\n"
    "Answer ONLY questions related to the MCP practical course content, including tool invocation, streaming, LangGraph, API design, etc. "
    "If the user question is NOT related to the course, reply: 'æˆ‘ä¸èƒ½å›ç­”ä¸ MCP æŠ€æœ¯å®æˆ˜å…¬å¼€è¯¾æ— å…³çš„é—®é¢˜ã€‚' "
    "You may call the provided tool `retriever_tool` when additional context is required."
)

GRADE_PROMPT = (
    "You are a grader assessing relevance of a retrieved document to a user question.\n"
    "Retrieved document:\n{context}\n\nUser question: {question}\n"
    "Return 'yes' if relevant, otherwise 'no'."
)

REWRITE_PROMPT = (
    "You are rewriting user questions to make them more relevant to the MCP technical practical course.\n"
    "Note: In this context, **MCP stands for Model Context Protocol**, an open framework for enabling large language models to use external tools and structured APIs.\n"
    "Do NOT interpret MCP as Microsoft Certified Professional.\n"
    "Your job is to refine or clarify the user's question to make it better aligned with key concepts from the Model Context Protocol course, such as tool invocation, tool registration, streaming APIs, LangGraph workflows, etc.\n\n"
    "Original question:\n{question}\nImproved question:"
)

ANSWER_PROMPT = (
    "You are an assistant for answering questions related to the MCP technical practical course. "
    "Use the provided context to answer the question as completely and accurately as possible. "
    "Whenever relevant, include examples, code blocks, or image references that appear in the source material. "
    "Use standard Markdown format for your output.\n\n"
    
    "Guidelines:\n"
    "- Prefer quoting code snippets using triple backticks (```) to preserve formatting.\n"
    "- If the context includes Markdown images (e.g. ![alt](url)), and the image is relevant, you may include it in the response.\n"
    "- Keep the response structured and easy to read with proper Markdown sections if needed.\n"
    "- If the answer is unknown or not present in the context, say: 'æˆ‘ä¸çŸ¥é“ã€‚'\n\n"

    "Question: {question}\n"
    "Context: {context}"
)

# ---------------------------------------------------------------------------
# LangGraph Nodes
# ---------------------------------------------------------------------------
async def generate_query_or_respond(state: MessagesState):
    """LLM decides to answer directly or call retriever tool."""
    response = await model.bind_tools([retriever_tool]).ainvoke(
        [
            {"role": "system", "content": SYSTEM_INSTRUCTION},
            *state["messages"],
        ]
    )
    return {"messages": [response]}


class GradeDoc(BaseModel):
    binary_score: str = Field(description="Relevance score 'yes' or 'no'.")


async def grade_documents(state: MessagesState) -> Literal["generate_answer", "rewrite_question"]:
    question = state["messages"][0].content  # original user question
    ctx = state["messages"][-1].content      # retriever output
    prompt = GRADE_PROMPT.format(question=question, context=ctx)
    result = await grader_model.with_structured_output(GradeDoc).ainvoke([
        {"role": "user", "content": prompt}
    ])
    return "generate_answer" if result.binary_score.lower().startswith("y") else "rewrite_question"


async def rewrite_question(state: MessagesState):
    question = state["messages"][0].content
    prompt = REWRITE_PROMPT.format(question=question)
    resp = await model.ainvoke([{"role": "user", "content": prompt}])
    return {"messages": [{"role": "user", "content": resp.content}]}


async def generate_answer(state: MessagesState):
    question = state["messages"][0].content
    ctx = state["messages"][-1].content
    prompt = ANSWER_PROMPT.format(question=question, context=ctx)
    resp = await model.ainvoke([{"role": "user", "content": prompt}])
    return {"messages": [resp]}

# ---------------------------------------------------------------------------
# Build graph
# ---------------------------------------------------------------------------
workflow = StateGraph(MessagesState)
workflow.add_node("generate_query_or_respond", generate_query_or_respond)
workflow.add_node("retrieve", ToolNode([retriever_tool]))
workflow.add_node("rewrite_question", rewrite_question)
workflow.add_node("generate_answer", generate_answer)

workflow.add_edge(START, "generate_query_or_respond")
workflow.add_edge("generate_query_or_respond", "retrieve")
workflow.add_conditional_edges("retrieve", grade_documents)
workflow.add_edge("generate_answer", END)
workflow.add_edge("rewrite_question", "generate_query_or_respond")

rag_agent = workflow.compile(name="rag_agent")
```

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250728201526589.png" alt="image-20250728201526589" style="zoom:50%;" />

ä»£ç è§£é‡Šå¦‚ä¸‹ï¼š

####  1. ç¯å¢ƒä¸ä¾èµ–åŠ è½½

```python
from __future__ import annotations
import os
import asyncio
from typing import Literal
from dotenv import load_dotenv 
load_dotenv(override=True)
```

- `__future__.annotations`: ä½¿ Python 3.7+ æ”¯æŒå»¶è¿Ÿæ³¨è§£è§£æï¼ˆé¿å…å¾ªç¯å¼•ç”¨ç­‰é—®é¢˜ï¼‰ã€‚
- `load_dotenv(override=True)`: åŠ è½½ `.env` ç¯å¢ƒå˜é‡æ–‡ä»¶ä¸­çš„å†…å®¹ï¼ˆå¦‚ API keyï¼‰ï¼Œå¹¶å…è®¸è¦†ç›–å·²æœ‰å˜é‡ã€‚

####  2. åˆå§‹åŒ– LLM æ¨¡å‹ä¸åµŒå…¥æ¨¡å‹

```python
from langchain.chat_models import init_chat_model
from langchain_openai import OpenAIEmbeddings
```

- `init_chat_model(...)`: åˆå§‹åŒ– `deepseek-chat` æ¨¡å‹ï¼ˆæ¥è‡ª DeepSeek çš„å¯¹è¯å¼å¤§æ¨¡å‹ï¼‰ã€‚
- `OpenAIEmbeddings(...)`: ä½¿ç”¨ OpenAI çš„ `text-embedding-3-small` åµŒå…¥æ¨¡å‹ï¼Œå°†æ–‡æœ¬è½¬ä¸ºå‘é‡ç”¨äºå‘é‡æ£€ç´¢ã€‚

```python
MODEL_NAME = "deepseek-chat"
model = init_chat_model(model=MODEL_NAME, model_provider="deepseek", temperature=0)
grader_model = init_chat_model(model=MODEL_NAME, model_provider="deepseek", temperature=0)
```

- `model`ï¼šä¸»æ¨¡å‹ï¼Œç”¨äºç”¨æˆ·å¯¹è¯å¤„ç†ã€‚
- `grader_model`ï¼šç”¨äºåˆ¤æ–­æ–‡æ¡£ç›¸å…³æ€§çš„å°åŠ©æ‰‹æ¨¡å‹ã€‚

####  3. å‘é‡æ•°æ®åº“åŠ è½½ä¸æ£€ç´¢å·¥å…·æ„å»º

```python
VS_PATH = "mcp_course_materials_db"
vector_store = FAISS.load_local(...)
retriever_tool = create_retriever_tool(...)
```

- ä»æœ¬åœ°åŠ è½½ä¸€ä¸ªåä¸º `mcp_course_materials_db` çš„ FAISS å‘é‡åº“ï¼›
- ä½¿ç”¨ `create_retriever_tool` æ„é€ äº†ä¸€ä¸ªå¯ä¾› LangGraph å·¥å…·è°ƒç”¨çš„ **Retriever å·¥å…·**ï¼ˆç”¨äºæŸ¥æ‰¾ä¸é—®é¢˜ç›¸å…³çš„æ–‡æœ¬å—ï¼‰ï¼›
- `k=3` è¡¨ç¤ºæ¯æ¬¡æ£€ç´¢è¿”å›3æ¡ä¸Šä¸‹æ–‡ã€‚

####  4. æç¤ºè¯è®¾è®¡ï¼ˆPrompt Engineeringï¼‰

è¿™äº›æç¤ºè¯æ˜¯å¯¹æ™ºèƒ½ä½“è¡Œä¸ºçš„æŒ‡ä»¤è®¾è®¡ã€‚

ç³»ç»Ÿæç¤ºè¯

```python
SYSTEM_INSTRUCTION = (...)
```

- é™å®šåŠ©æ‰‹åªèƒ½å›ç­”â€œ**Model Context Protocol (MCP)**â€æŠ€æœ¯å®æˆ˜ç›¸å…³é—®é¢˜ï¼›
- å¦‚æœä¸æ˜¯ç›¸å…³é—®é¢˜ï¼Œå°±å›å¤ï¼šæˆ‘ä¸èƒ½å›ç­”ä¸ MCP æŠ€æœ¯å®æˆ˜å…¬å¼€è¯¾æ— å…³çš„é—®é¢˜ã€‚

è¯„ä¼° Prompt

```python
GRADE_PROMPT = (...)
```

- æŒ‡å¯¼ `grader_model` åˆ¤æ–­æ£€ç´¢ç»“æœæ˜¯å¦ä¸ç”¨æˆ·æé—®ç›¸å…³ï¼Œè¾“å‡º `yes` æˆ– `no`ã€‚

é‡å†™ Prompt

```python
REWRITE_PROMPT = (...)
```

- å¦‚æœç”¨æˆ·é—®é¢˜åç¦»ä¸»é¢˜ï¼Œè®©æ¨¡å‹æ”¹å†™é—®é¢˜ï¼Œä½¿å…¶æ›´è´´è¿‘â€œå·¥å…·è°ƒç”¨ / LangGraph / MCPâ€ç­‰å…³é”®æ¦‚å¿µã€‚

å›ç­” Prompt

```python
ANSWER_PROMPT = (...)
```

- ç»™æ¨¡å‹ä¸€ä¸ªé—®é¢˜å’Œä¸Šä¸‹æ–‡ï¼Œå¼•å¯¼å®ƒç”¨ Markdownã€ä»£ç å—ã€å›¾ç‰‡ç­‰æ–¹å¼ç”Ÿæˆç»“æ„åŒ–ç­”æ¡ˆã€‚

####  5. LangGraph èŠ‚ç‚¹é€»è¾‘å®šä¹‰

LangGraph æ˜¯æœ‰çŠ¶æ€å¤šèŠ‚ç‚¹çš„å›¾ç»“æ„ï¼Œè¿™é‡Œå®šä¹‰äº†æ™ºèƒ½ä½“å¯¹è¯çš„å„ä¸ªèŠ‚ç‚¹åŠŸèƒ½ã€‚

âœ… generate_query_or_respond

```python
async def generate_query_or_respond(state: MessagesState):
    ...
```

- è°ƒç”¨ LLMï¼Œæ ¹æ®å½“å‰æ¶ˆæ¯å†³å®šæ˜¯å¦è¦è°ƒç”¨ `retriever_tool`ï¼›
- æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªå…·å¤‡å·¥å…·è°ƒç”¨èƒ½åŠ›çš„äº¤äº’èŠ‚ç‚¹ï¼ˆå¦‚æœä¸Šä¸‹æ–‡ä¸è¶³ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨å†³å®šè°ƒç”¨æ£€ç´¢å™¨ï¼‰ã€‚

âœ… grade_documents

```python
async def grade_documents(state: MessagesState) -> Literal["generate_answer", "rewrite_question"]:
    ...
```

- ä½¿ç”¨ `grader_model` åˆ¤æ–­ï¼šæ£€ç´¢åˆ°çš„æ–‡æ¡£æ˜¯å¦ä¸æé—®æœ‰å…³ï¼›
- å¦‚æœæ˜¯ â†’ `generate_answer`ï¼›
- å¦‚æœä¸æ˜¯ â†’ `rewrite_question`ã€‚

âœ… rewrite_question

```python
async def rewrite_question(state: MessagesState):
    ...
```

- è°ƒç”¨ LLM æ”¹å†™ç”¨æˆ·é—®é¢˜ï¼Œä½¿å…¶æ›´ç¬¦åˆ MCP è¯¾ç¨‹èŒƒç•´ã€‚

âœ… generate_answer

```python
async def generate_answer(state: MessagesState):
    ...
```

- ç”¨ LLM + ä¸Šä¸‹æ–‡ç”Ÿæˆæœ€ç»ˆç­”å¤ï¼›
- æ”¯æŒä»£ç å—ä¸ Markdown æ ¼å¼ã€‚

#### ğŸ§­ 6. æ„å»º LangGraph å·¥ä½œæµ

```python
workflow = StateGraph(MessagesState)
```

æˆ‘ä»¬å°†æ‰€æœ‰é€»è¾‘èŠ‚ç‚¹é€šè¿‡å›¾ç»“æ„ç»„åˆæˆä¸€ä¸ªå®Œæ•´æ™ºèƒ½ä½“æµç¨‹ï¼š

```mermaid
graph TD
    START --> generate_query_or_respond
    generate_query_or_respond --> retrieve
    retrieve --> grade_documents
    grade_documents -- yes --> generate_answer --> END
    grade_documents -- no --> rewrite_question --> generate_query_or_respond
```

è§£é‡Šå¦‚ä¸‹ï¼š

| æ­¥éª¤ | èŠ‚ç‚¹åç§°                    | åŠŸèƒ½                   |
| ---- | --------------------------- | ---------------------- |
| 1    | `START`                     | èµ·ç‚¹                   |
| 2    | `generate_query_or_respond` | æ¨¡å‹åˆ¤æ–­æ˜¯å¦è°ƒç”¨å·¥å…·   |
| 3    | `retrieve`                  | è°ƒç”¨æ£€ç´¢å·¥å…·è¿”å›ä¸Šä¸‹æ–‡ |
| 4    | `grade_documents`           | åˆ¤æ–­æ£€ç´¢ç»“æœæ˜¯å¦ç›¸å…³   |
| 5a   | `generate_answer`           | ç”Ÿæˆå›ç­” â†’ ç»ˆç‚¹        |
| 5b   | `rewrite_question`          | æ”¹å†™é—®é¢˜ â†’ å›åˆ°ç¬¬2æ­¥   |

####  7. ç¼–è¯‘æ™ºèƒ½ä½“å¹¶ç”Ÿæˆå…¥å£

```python
rag_agent = workflow.compile(name="rag_agent")
```

æœ€ç»ˆå°†æ•´ä¸ª LangGraph å›¾ç¼–è¯‘ä¸ºå¯è°ƒç”¨çš„ `rag_agent`ï¼Œä½ å¯ä»¥åœ¨ä¸»å‡½æ•°ä¸­è¿™æ ·è°ƒç”¨ï¼š

```python
await rag_agent.ainvoke({"messages": [{"role": "user", "content": "MCP æ˜¯ä»€ä¹ˆï¼Ÿ"}]})
```

å®é™…æµ‹è¯•æ•ˆæœå¦‚ä¸‹ï¼š

<video src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/2025-07-28%2020-31-27.mp4"></video>

<video src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/2025-07-29%2016-30-54.mp4"></video>

---

- ä½“éªŒè¯¾å†…å®¹èŠ‚é€‰è‡ª[ã€Š2025å¤§æ¨¡å‹Agentæ™ºèƒ½ä½“å¼€å‘å®æˆ˜ã€‹(ç§‹æ‹›å†²åˆºç­)](https://ix9mq.xetslk.com/s/2S2Vpy)å®Œæ•´ç‰ˆä»˜è´¹è¯¾ç¨‹

&emsp;&emsp;ä½“éªŒè¯¾æ—¶é—´æœ‰é™ï¼Œè‹¥æƒ³æ·±åº¦å­¦ä¹ å¤§æ¨¡å‹æŠ€æœ¯ï¼Œæ¬¢è¿å¤§å®¶æŠ¥åç”±æˆ‘ä¸»è®²çš„[ã€Š2025å¤§æ¨¡å‹Agentæ™ºèƒ½ä½“å¼€å‘å®æˆ˜ã€‹(ç§‹æ‹›å†²åˆºç­)](https://ix9mq.xetslk.com/s/2S2Vpy)

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/06661cb459aa3e4b655aface404435d.png" alt="06661cb459aa3e4b655aface404435d" style="zoom:15%;" />

**[ã€Š2025å¤§æ¨¡å‹Agentæ™ºèƒ½ä½“å¼€å‘å®æˆ˜ã€‹(ç§‹æ‹›å†²åˆºç­)](https://ix9mq.xetslk.com/s/2S2Vpy)ä¸ºã€100+å°æ—¶ã€‘ä½“ç³»å¤§è¯¾ï¼Œæ€»å…±20å¤§æ¨¡å—ç²¾è®²ç²¾æï¼Œé›¶åŸºç¡€ç›´è¾¾å¤§æ¨¡å‹ä¼ä¸šçº§åº”ç”¨ï¼**

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506172010074.png" alt="a55d48e952ed59f8d93e050594843bc" style="zoom:50%;" />

### éƒ¨åˆ†è¯¾ç¨‹æˆæœæ¼”ç¤º

- Dify+DeepSeekæ­å»ºæ™ºèƒ½å®¢æœ

<video src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/2f1b47f42c65fd59e8d3a83e6cb9f13b_raw.mp4"></video>

- Cozeè‡ªåŠ¨å›¾æ–‡è§†é¢‘åˆ›ä½œæµç¨‹

<video src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/Coze%E5%8A%A8%E6%80%81%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E5%AE%9E%E4%BE%8B.mp4"></video>

- å¯è§†åŒ–æ•°æ®åˆ†æMulti-Agent

<video src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/%E5%8F%AF%E8%A7%86%E5%8C%96%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90Multi-Agent%E6%95%88%E6%9E%9C%E6%BC%94%E7%A4%BA%E6%95%88%E6%9E%9C.mp4"></video>

- Ollama è‡ªåŠ¨åŒ–å¹¶å‘è¯·æ±‚æµ‹è¯•ä¸åŠ¨æ€èµ„æºç›‘æ§

<video src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/3.Ollama%20%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B9%B6%E5%8F%91%E8%AF%B7%E6%B1%82%E6%B5%8B%E8%AF%95%E4%B8%8E%E5%8A%A8%E6%80%81%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7.mp4"></video>

- Neo4jå¹¶è¡Œå¤šçº¿ç¨‹å¯¼å…¥ç™¾ä¸‡çº§æ–‡æœ¬æ–¹æ³•ä¸å®è·µ

<video src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/2.Neo4j%E5%B9%B6%E8%A1%8C%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AF%BC%E5%85%A5%E7%99%BE%E4%B8%87%E7%BA%A7%E6%96%87%E6%9C%AC%E6%96%B9%E6%B3%95%E4%B8%8E%E5%AE%9E%E6%88%98%E6%BC%94%E7%A4%BA.mp4"></video>

- é«˜æ•ˆå¾®è°ƒå…¨è‡ªåŠ¨æ•°æ®é›†åˆ›å»º

<video src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/easy_daset_yanshi.mp4"></video>

- MateGen Pro é¡¹ç›®åŠŸèƒ½æ¼”ç¤º

<video src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/MG%E6%BC%94%E7%A4%BA%E8%A7%86%E9%A2%91.mp4"></video>

- æ™ºèƒ½å®¢æœé¡¹ç›®å±•ç¤º

<video src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D%E6%A1%88%E4%BE%8B%E8%A7%86%E9%A2%91.mp4"></video>

- **GraphRAG+å¤šæ¨¡æ€æ–‡æ¡£æ£€ç´¢**

<video src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/7%E6%9C%8817%E6%97%A5%281%29%20%E8%BF%9B%E5%BA%A6%E6%9D%A1.mp4"></video>

æ­¤å¤–ï¼Œè‹¥æ˜¯å¯¹å¤§æ¨¡å‹åº•å±‚åŸç†æ„Ÿå…´è¶£ï¼Œä¹Ÿæ¬¢è¿æŠ¥åç”±æˆ‘å’Œèœèœè€å¸ˆå…±åŒä¸»è®²çš„[ã€Š2025å¤§æ¨¡å‹åŸç†ä¸å®æˆ˜è¯¾ç¨‹ã€‹(ç§‹æ‹›å†²åˆºç­)](https://ix9mq.xetslk.com/s/3AME7R)

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506171650709.png" alt="4a11b7807056e9f5b281278c0e37dad" style="zoom:20%;" />

**å¤§æ¨¡å‹ç§‹æ‹›å†²åˆºç­å¼€ç­ç‰¹æƒ è¿›è¡Œä¸­ï¼Œç›´æ’­é—´äº«äº”æŠ˜ç‰¹ä»·+å…¨å¥—SVIPæ–°ç­ç‰¹å®šç¦åˆ©ï¼Œåˆè´­è¿˜æœ‰æ›´å¤šä¼˜æƒ å“¦~<span style="color:red;">è¯¦ç»†ä¿¡æ¯æ‰«ç æ·»åŠ åŠ©æ•™ï¼Œå›å¤â€œå¤§æ¨¡å‹â€ï¼Œå³å¯é¢†å–è¯¾ç¨‹å¤§çº²&æŸ¥çœ‹è¯¾ç¨‹è¯¦æƒ…ğŸ‘‡</span>**

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/26449c9c3e90ea66e0af9150ad00e0c6.png" alt="26449c9c3e90ea66e0af9150ad00e0c6" style="zoom:50%;" />

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/0d489e9d3c29af2d7f319171eac040d0.png" alt="0d489e9d3c29af2d7f319171eac040d0" style="zoom:50%;" />







